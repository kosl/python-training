{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e0bcb58-12d9-4dc4-b6e7-e90f3828c379",
   "metadata": {},
   "source": [
    "### Introduction to Dask\n",
    "\n",
    "<img src=\"https://docs.dask.org/en/latest/_images/dask_horizontal.svg\"\n",
    "     align=\"right\"\n",
    "     width=\"20%\"\n",
    "     alt=\"Dask logo\\\">\n",
    "\n",
    "Dask is an open-source Python library for parallel computing. Dask can scale Python code from multi-core local machines to large distributed clusters, without the code having to be altered a great deal. Dask provides a familiar user interface by mirroring the APIs of other libraries in Python, such as pandas and NumPy. It also enables programmers to run custom algorithms in parallel. It does so by creating lazy, delayed objects. These objects hold the \"recipe\" of how to compute a certain task, without actually performing the computation. These objects are saved in memory as task graphs, wich can be visualized to get a better handle on the actual parallelisaton that is taking place. To actually get the desired numerical result, the task graph has to be passed on to a task scheduler which then performs the computation in parallel.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "    \n",
    "<img src=\"images/dask-overview.svg\" align=\"center\" width=\"60%\">\n",
    "\n",
    "High level collections are used to generate task graphs which can be executed by schedulers on a single machine or a cluster. Source: https://docs.dask.org/en/stable/10-minutes-to-dask.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b733fc58-7d23-4656-ab01-1fd42f5a3441",
   "metadata": {},
   "source": [
    "## Dask cluster overview\n",
    "\n",
    "In this section we'll discuss:\n",
    "\n",
    "1. The different components which make up a Dask cluster\n",
    "2. Survey different ways to launch a cluster\n",
    "\n",
    "### Components of a Dask cluster\n",
    "\n",
    "A Dask cluster is composed of three different types of objects:\n",
    "\n",
    "1. **Scheduler**: A single, centralized scheduler process which responds to requests for computations, maintains relavant state information about tasks and workers, and sends tasks to workers to be computed.\n",
    "2. **Workers**: One or more worker processes which compute tasks and store their results.\n",
    "3. **Clients**: Client objects are the user-facing entry point to interact with the cluster.\n",
    "\n",
    "<img src=\"./images/dask-cluster.png\"\n",
    "     width=\"70%\"\n",
    "     alt=\"Dask components\\\">\n",
    "     \n",
    "\n",
    "### Nodes on an HPC cluster\n",
    "\n",
    "An HPC cluster has login nodes on wich users prepare their job scripts etc. without performing expensive computations. For that, an HPC cluster has compute nodes which are allocated by the resource manager (in this case PBS). To access the login nodes you need to SSH from the command line.\n",
    "At some clusters (like the Vienna Scientific Cluster, VSC), you can access a compute node directly via JupyterHub. VCS users can get resources for JupyterHub of one node max. To get more compute power they need to submit a job script, just as on a login node.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"./images/VSC_Cluster.png\"\n",
    "     width=50%\n",
    "     alt=\"Nodes of VSC\\\"\n",
    "     align=\"center\">\n",
    "<br>\n",
    "<br>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded8e272-8efa-4e28-97e8-ebf418dda796",
   "metadata": {},
   "source": [
    "### Setting up the ports for communication\n",
    "\n",
    "This step is necessary, since we are many users each trying to setup our own Dask client to launch workers from and monitor them with the diagnostic tools the Dask dashboard offers. Since we run into trouble when some of us are using the same port, we came up with the Python code below, to ensure we are not getting in each other's way. You do not need this step when working on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a248bc6-45fa-4336-8335-2c7f7d60d44c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954a77f-7940-4ef8-98e8-34fe7d179d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dask\n",
    "import dask.config\n",
    "import dask.distributed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e68894f-90b6-4aae-aee8-56146cb437f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "USER = os.environ.get(\"USER\")\n",
    "if USER.startswith(\"dd-23-22-\"):\n",
    "    user_number = int(USER.replace(\"dd-23-22-\", \"\"))\n",
    "else:\n",
    "    user_number = 100\n",
    "\n",
    "# We all need different ports for our dashboards and schedulers.\n",
    "DASHBOARD_PORT = 45000 + user_number \n",
    "SCHEDULER_PORT = 46000 + user_number\n",
    "#####\n",
    "\n",
    "print('dashboard port:', DASHBOARD_PORT)\n",
    "print('scheduler port:', SCHEDULER_PORT)\n",
    "\n",
    "#dask.config.set({'temporary_directory': f'/tmp/dask-{USER}'})\n",
    "#print('temp dir: ', dask.config.get(\"temporary_directory\"))\n",
    "\n",
    "#dask.config.set({\"distributed.dashboard.link\": f\"/user/{USER}/proxy/{DASHBOARD_PORT}/status\"})\n",
    "#print('dashboard link: ', dask.config.get(\"distributed.dashboard.link\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cc17e6-c8e9-4a33-bddd-dc67d0e5fb8b",
   "metadata": {},
   "source": [
    "### Distributed scheduler on a local machine\n",
    "\n",
    "The `dask.distributed` system is composed of a single centralized scheduler and one or more worker processes. [Deploying](https://docs.dask.org/en/latest/setup.html) a remote Dask cluster involves some additional effort. But doing things locally it just involves creating a `Client` object, which lets you interact with the \"cluster\" (local threads or processes on your machine). For more information see [here](https://docs.dask.org/en/latest/setup/single-distributed.html). \n",
    "\n",
    "You could create a Dask cluster on your own PC, however, in this case we are on a node running VSC's JupyterHub. With LocalCluster, you only use the resources avaliable to you on the specific node you are on. If you want to leverage the compute power of the entire VSC by submitting jobs to SLURM (resource manager on VSC), you need Dask's SLURMCluster (see further down). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057bbd93-86e9-4ff7-bd6e-186e521c1dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster\n",
    "\n",
    "# Launch a scheduler and 4 workers on my local machine\n",
    "cluster = LocalCluster(n_workers=4, threads_per_worker=2, scheduler_port=SCHEDULER_PORT, dashboard_address=DASHBOARD_PORT)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bdfe51-582a-460a-8483-45f182448f04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832bf89a-a40a-459b-9987-f32eca84291f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a043e2c9-4369-406e-913b-598f533f0926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale up to 10 workers\n",
    "cluster.scale(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2efb79-16bb-4e25-8678-b95c63b3edc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale down to 2 workers\n",
    "cluster.scale(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a926bf-255b-4549-9804-53e9023d8bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve cluster logs\n",
    "cluster.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44185943-9c0f-4d05-84ed-b5cc5ca28902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Caution is required when scaling on a cluster.\n",
    "# Dask might terminate a worker at a memory use which is too high.\n",
    "# To change that, modify ~/.config/dask/distributed.yaml accordingly.\n",
    "\n",
    "from dask.distributed import system\n",
    "\n",
    "system.MEMORY_LIMIT/1024/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50330cf8-917f-448e-9b71-8947523f5c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if client:\n",
    "    client.close()\n",
    "    client = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f83cd3-eebf-4566-a80b-0e04f3b768f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cluster:\n",
    "    cluster.close()\n",
    "    cluster = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3388f7f-3fce-4727-bf51-655afefc5808",
   "metadata": {},
   "source": [
    "### Distributed scheduler on a remote machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aec191a-0ab3-4ef3-8b0d-df7488f78399",
   "metadata": {
    "tags": []
   },
   "source": [
    "There are several projects in the Dask ecosystem for easily deploying clusters on commonly used computing resources:\n",
    "\n",
    "- [Dask-Kubernetes](https://kubernetes.dask.org/en/latest/) for deploying Dask using native Kubernetes APIs\n",
    "- [Dask-Cloudprovider](https://cloudprovider.dask.org/en/latest/) for deploying Dask clusters on various cloud platforms (e.g. AWS, GCP, Azure, etc.)\n",
    "- [Dask-Yarn](https://yarn.dask.org/en/latest/) for deploying Dask on YARN clusters\n",
    "- [Dask-MPI](http://mpi.dask.org/en/latest/) for deploying Dask on existing MPI environments\n",
    "- [Dask-Jobqueue](https://jobqueue.dask.org/en/latest/) for deploying Dask on job queuing systems (e.g. PBS, Slurm, etc.)\n",
    "\n",
    "Launching clusters with any of these projects follows a similar pattern as using Dask's built-in `LocalCluster`:\n",
    "\n",
    "```python\n",
    "# Launch a Dask cluster on a Kubernetes cluster\n",
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster(...)\n",
    "\n",
    "# Launch a Dask cluster on AWS Fargate\n",
    "from dask_cloudprovider.aws import FargateCluster\n",
    "cluster = FargateCluster(...)\n",
    "\n",
    "# Launch a Dask cluster on a Slurm job queueing system\n",
    "from dask_jobqueue import SLURMCluster\n",
    "cluster = SLURMCluster(...)\n",
    "```\n",
    "\n",
    "#### Related Documentation\n",
    "\n",
    "- [Cluster setup](https://docs.dask.org/en/latest/setup.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8814a-09fd-4d72-a715-bc5d89e0076e",
   "metadata": {},
   "source": [
    "Now we need to specify the hardware we want for our cluster. Note that the cores and memory are just what you want from one node. Later we will scale that to our requirements. As we would like to get through the PBS queue as quickly as possible, it makes sense to use fewer cores and memory and set a shorter walltime for each worker, but then scale the number of workers accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa7e18-288f-4875-a1b6-387fd17dc5e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if client:\n",
    "    client.close()\n",
    "    client = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5fab3-36a4-499c-b875-19e219372e93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cluster:\n",
    "    cluster.close()\n",
    "    cluster = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d8de25-8796-4d27-bdc1-52bfb4953f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dask_jobqueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee99c033-c8e5-448b-a1cd-099b091d0518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask_jobqueue import PBSCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1bb26e-a3e7-44c3-982a-d8a75b4ce241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#PBSCluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7c3d52-cba0-468c-ad6a-4df41b2dc58a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster = PBSCluster(cores=64,\n",
    "                     memory = \"4 GB\",\n",
    "                     queue = \"qcpu\",\n",
    "                     account=\"DD-23-22\",\n",
    "                     walltime=\"00:05:00\",\n",
    "                     scheduler_options={\n",
    "                           \"interface\": \"ib0\",\n",
    "                           \"dashboard_address\": f\":{DASHBOARD_PORT}\",\n",
    "                           \"port\": SCHEDULER_PORT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4c1ca-630f-4ffc-8410-bef32dec777b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f684105-b6e7-4eeb-8d14-166467138c65",
   "metadata": {},
   "source": [
    "Unfortunately this does not work out of out of a singularity container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216fcd34-1c8c-4024-9095-c83d6d04aafa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!qstat -u $USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e4e32-1252-4b3d-ad76-f7f525440f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.scale(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400b171-909c-4baf-b4d5-9c056bbfff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "!qstat -u $USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb80835f-6491-452f-a46f-9ddcbc64a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7383224c-559b-43e8-9e8e-f2ab23a593c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da2a30-e505-4c33-b791-56e6bade2824",
   "metadata": {},
   "source": [
    "Most Dask deployments are static with a single scheduler and a fixed number of workers. This results in predictable behavior, but is wasteful of resources in two situations:\n",
    "\n",
    "* The user may not be using the cluster, or perhaps they are busy interpreting a recent result or plot, and so the workers sit idly, taking up valuable shared resources from other potential users\n",
    "\n",
    "* The user may be very active, and is limited by their original allocation.\n",
    "\n",
    "Adaptive deployments are particularly helpful for interactive workloads, which are characterized by long periods of inactivity interrupted with short bursts of heavy activity. They can result in both faster analyses that give users much more power, but with much less pressure on computational resources.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"images/dask-adaptive.svg\"\n",
    "     width=50%\n",
    "     alt=\"Nodes of VSC\\\"\n",
    "     align=\"center\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f0d3a7-05ea-4076-a24d-fe3845b24856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.adapt(minimum_jobs=0, maximum_jobs=60)  # scale between 0 and 20 workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0ea078-c5b1-4dc6-9994-c11a152ae561",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!qstat -u $USER # It might take some time for the jobs to become visible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db78794a-353e-4acd-9621-6e1c9248b2ea",
   "metadata": {},
   "source": [
    "### Executing with the distributed client\n",
    "Let's see what our dask cluster can achieve with this computationally challenging calculation. Note that you might have to wait until sufficient workers are running in the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5ccfa-7c2d-4dc6-a88c-86eac576fc7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2159b6c-078b-46f7-b5fd-7d9b0bb6f8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.scale(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece6cf98-d82b-466e-b208-37a7b63a4f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = da.random.random((10_000,10_000,10), chunks=(1000,1000,5))\n",
    "y = da.random.random((10_000,10_000,10), chunks=(1000,1000,5))\n",
    "z = (da.arcsin(x) + da.arccos(y)).sum(axis=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c290999b-2629-491a-aa84-e9258caf4239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2542ba-1c64-47cd-bc31-3241065ea5bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fabea0-f551-4f58-bd5c-f7cc5d6e9db2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bfa8c0-2a33-4ed6-a0a5-d4741aee205b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z.dask.visualize() # High level graph. Low level graph with z.visualize(), but this would be overwhelming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528c324c-1028-4ef4-8bdc-58002d672df8",
   "metadata": {},
   "source": [
    "By default, creating a `Client` makes it the default scheduler. Any calls to `.compute` will use the cluster your `client` is attached to, unless you specify otherwise, as above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ba0dad-0812-4068-85ea-8b99fed22458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.close()\n",
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba238fc-744b-4efd-a81b-b8d571c26642",
   "metadata": {},
   "source": [
    "Since some of you will be dealing with the SLURM scheduler on other HPC clusters, the code below shows you how you could set up a SLURMCluster:\n",
    "```python\n",
    "from dask_jobqueue import SLURMCluster\n",
    "cluster = SLURMCluster(queue=\"skylake_0096\", # this is the partition we want to use\n",
    "                       account=\"p70824\", # this is the account used for billing\n",
    "                       cores=16,          # number of cores per SLURM job\n",
    "                       processes=4,      # number of python dask-worker processes per SLURM job\n",
    "                       name=f'{USER}-worker',  # custom name of workers\n",
    "                       memory=\"4GB\",     # memory one SLURM job should have avaliable (will be divided by number of worker processes in job)\n",
    "                       walltime=\"00:05:00\",\n",
    "                       interface=\"ib0\",  # ib0 is infiniband, the fast network connection\n",
    "                       scheduler_options={\n",
    "                           \"interface\": \"ib0\",\n",
    "                           \"dashboard_address\": f\":{DASHBOARD_PORT}\",\n",
    "                           \"port\": SCHEDULER_PORT\n",
    "                       },\n",
    "                       # worker_extra_args=[\"--lifetime\", \"4m\", \"--lifetime-stagger\", \"2m\"],\n",
    "                       # lifetime ensures that workers will be properly shut down before the scheduling system kills them, and all their states moved.\n",
    "                       # lifetime-stagger will prevent workers from terminating at the same time, thus ease rebalancing tasks and scheduling burden.\n",
    "                       job_directives_skip=[\n",
    "                           '-J dask-worker',\n",
    "                       ],\n",
    "                       job_extra_directives=[\n",
    "                           f'--job-name={USER}-worker',\n",
    "                           '--qos=skylake_0096',\n",
    "                           #'--reservation=training', # only to be used during this training                          \n",
    "                       ]) \n",
    "print(cluster.job_script()) # this is turned into a job script\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5a64b-664b-46d6-8fb8-953507d601ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
